{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise and PESTPP-IES\n",
    "\n",
    "As discussed previously, formal data assimilation methods (including ensemble methods such as those encoded in PESTPP-IES) explicitly recognize and make use of expected noise in the observations being assimilated.  While it may be tempting to think of this noise as simply \"measurement noise\", its actually much more complicated than that.  This noise should account for any expected deficiencies in the ability of the model to simulate the scales and processes that \"generated\" the observations.  That is, this noise should (attempt to) account for model error - yikes!  Well, what do we know about model error and how it manifests during the history matching process.  Previous theoretical and empirical works have shown that this \"noise\" is likely to be higly correlated in space and in time, and that this correlation probably cant be described by a simple (auto)correlation function, which sucks.  But just because we cant get something perfect, doesnt mean we can (greatly) improve upon it.\n",
    "\n",
    "Let's take a deeper dive into the realm of noise..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Current Tutorial\n",
    "\n",
    "In the current notebook we are going to pick up after the [\"ies_1_basics\"](../part2_06_ies/freyberg_ies_1_basics.ipynb) tutorial. We setup PEST++IES and ran it. We found that we can achieve great fits with historical data...but that (for some forecasts) the calculated posterior probabilities failed to cover the truth.\n",
    "\n",
    "In this tutorial we are going to take a first stab at fixing that. We are going to implement localization to remove the potential for spurious correlations between observations and parameters incurred by using an \"approximate\" partial derivatives.  \n",
    "\n",
    "### Admin\n",
    "\n",
    "The next couple of cells load necessary dependencies and call a convenience function to prepare the PEST dataset folder for you. Simply press `shift+enter` to run the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "import psutil\n",
    "\n",
    "import sys\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the template directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_template_extreme')\n",
    "\n",
    "org_t_d = os.path.join(\"master_ies_1\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/freyberg_ies_1_basics.ipynb' notebook\")\n",
    "\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "shutil.copytree(org_t_d,t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the previous run\n",
    "\n",
    "First we need to load the existing control file and results from the basic PESTPP-IES run we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_path = os.path.join(org_t_d, 'pest.pst')\n",
    "pst = pyemu.Pst(pst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot up the obs vs sim, including the noise realizations that PESTPP-IES generated for us using the `standard_deviation` column in \"* observation data\" section.  Here is our timeseries plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_hist_compare(pr_oe,pt_oe, last_pt_oe=None,last_prior=None ):\n",
    "        num_plots = len(pst.forecast_names)\n",
    "        num_cols = 1\n",
    "        if last_pt_oe is not None:\n",
    "            num_cols=2\n",
    "        fig,axes = plt.subplots(num_plots, num_cols, figsize=(5*num_cols,num_plots * 2.5), sharex='row',sharey='row')\n",
    "        for axs,forecast in zip(axes, pst.forecast_names):\n",
    "            # plot first column with currrent outcomes\n",
    "            if num_cols==1:\n",
    "                axs=[axs]\n",
    "            ax = axs[0]\n",
    "            # just for aesthetics\n",
    "            bin_cols = [pt_oe.loc[:,forecast], pr_oe.loc[:,forecast],]\n",
    "            if num_cols>1:\n",
    "                bin_cols.extend([last_pt_oe.loc[:,forecast],last_prior.loc[:,forecast]])\n",
    "            bins=np.histogram(pd.concat(bin_cols),\n",
    "                                         bins=20)[1] #get the bin edges\n",
    "            pr_oe.loc[:,forecast].hist(facecolor=\"0.5\",alpha=0.5, bins=bins, ax=ax,density=True)\n",
    "            pt_oe.loc[:,forecast].hist(facecolor=\"b\",alpha=0.5, bins=bins, ax=ax,density=True)\n",
    "            ax.set_title(forecast)\n",
    "            fval = pst.observation_data.loc[forecast,\"obsval\"]\n",
    "            ax.plot([fval,fval],ax.get_ylim(),\"r-\")\n",
    "            ax.set_yticks([])\n",
    "            # plot second column with other outcomes\n",
    "            if num_cols >1:\n",
    "                ax = axs[1]\n",
    "                last_prior.loc[:,forecast].hist(facecolor=\"0.5\",alpha=0.5, bins=bins, ax=ax,density=True)\n",
    "                last_pt_oe.loc[:,forecast].hist(facecolor=\"b\",alpha=0.5, bins=bins, ax=ax,density=True)\n",
    "                ax.set_title(forecast)\n",
    "                fval = pst.observation_data.loc[forecast,\"obsval\"]\n",
    "                ax.plot([fval,fval],ax.get_ylim(),\"r-\")\n",
    "                ax.set_yticks([])\n",
    "                \n",
    "        # set ax column titles\n",
    "        if num_cols >1:\n",
    "            axes.flatten()[0].text(0.5,1.2,\"Current Attempt\", transform=axes.flatten()[0].transAxes, weight='bold', fontsize=12, horizontalalignment='center')\n",
    "            axes.flatten()[1].text(0.5,1.2,\"Previous Attempt\", transform=axes.flatten()[1].transAxes, weight='bold', fontsize=12, horizontalalignment='center')\n",
    "        fig.tight_layout()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=org_t_d)\n",
    "ib = sim.get_model().dis.idomain.array[0,:,:]\n",
    "def plot_hk(pr_oe, pt_oe, pst):\n",
    "    obs = pst.observation_data\n",
    "    hkobs = obs.loc[obs.oname==\"hk\",:].copy()\n",
    "    hkobs[\"i\"] = hkobs.i.astype(int)\n",
    "    hkobs[\"j\"] = hkobs.j.astype(int)\n",
    "    real = pt_oe.index[0]\n",
    "    \n",
    "    fig,axes = plt.subplots(2,4,figsize=(15,10))\n",
    "    prmn,prstd,prmev,prreal = np.zeros_like(ib,dtype=float),np.zeros_like(ib,dtype=float),np.zeros_like(ib,dtype=float),np.zeros_like(ib,dtype=float)\n",
    "    prmn[hkobs.i,hkobs.j] = pr_oe.loc[:,hkobs.obsnme].mean()\n",
    "    prstd[hkobs.i,hkobs.j] = pr_oe.loc[:,hkobs.obsnme].std()\n",
    "    prmev[hkobs.i,hkobs.j] = pr_oe.loc[\"base\",hkobs.obsnme].values   \n",
    "    prreal[hkobs.i,hkobs.j] = pr_oe.loc[real,hkobs.obsnme].values   \n",
    "    ptmn,ptstd,ptmev,ptreal = np.zeros_like(ib,dtype=float),np.zeros_like(ib,dtype=float),np.zeros_like(ib,dtype=float),np.zeros_like(ib,dtype=float)\n",
    "    ptmn[hkobs.i,hkobs.j] = pt_oe.loc[:,hkobs.obsnme].mean()\n",
    "    ptstd[hkobs.i,hkobs.j] = pt_oe.loc[:,hkobs.obsnme].std()\n",
    "    ptmev[hkobs.i,hkobs.j] = pt_oe.loc[\"base\",hkobs.obsnme].values  \n",
    "    ptreal[hkobs.i,hkobs.j] = pt_oe.loc[real,hkobs.obsnme].values   \n",
    "    for arr in [prmn,prstd,prmev,prreal,ptmn,ptstd,ptmev,ptreal]:\n",
    "        #arr = np.log10(arr)\n",
    "        arr[ib>0] = np.log10(arr[ib>0])\n",
    "        arr[ib==0] = np.nan\n",
    "    prarrs = [prmn,prstd,prmev,prreal]\n",
    "    ptarrs = [ptmn,ptstd,ptmev,ptreal]\n",
    "    titles = [\"mean\",\"stdev\",\"MEV\",\"realization {0}\".format(real)]\n",
    "    \n",
    "    for pr,pt,axes,title in zip(prarrs,ptarrs,axes.transpose(),titles):\n",
    "        vmn,vmx = min(np.nanmin(pr),np.nanmin(pt)),max(np.nanmax(pr),np.nanmax(pt))\n",
    "        cb = axes[0].imshow(pr,vmin=vmn,vmax=vmx)\n",
    "        plt.colorbar(cb,ax=axes[0],label=\"$log_{10}\\\\frac{m}{d}$\")\n",
    "        axes[0].set_title(\"prior \"+title)\n",
    "        cb = axes[1].imshow(pt,vmin=vmn,vmax=vmx)\n",
    "        plt.colorbar(cb,ax=axes[1],label=\"$log_{10}\\\\frac{m}{d}$\")\n",
    "        axes[1].set_title(\"posterior \"+title)\n",
    "    plt.tight_layout()\n",
    "    return fig,axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tseries_ensembles(pr_oe, pt_oe, noise, onames=[\"hds\",\"sfr\"]):\n",
    "    pst.try_parse_name_metadata()\n",
    "    # get the observation data from the control file and select \n",
    "    obs = pst.observation_data.copy()\n",
    "    # onames provided in oname argument\n",
    "    obs = obs.loc[obs.oname.apply(lambda x: x in onames)]\n",
    "    # only non-zero observations\n",
    "    obs = obs.loc[obs.obgnme.apply(lambda x: x in pst.nnz_obs_groups),:]\n",
    "    # make a plot\n",
    "    ogs = obs.obgnme.unique()\n",
    "    fig,axes = plt.subplots(len(ogs),1,figsize=(10,2*len(ogs)))\n",
    "    ogs.sort()\n",
    "    # for each observation group (i.e. timeseries)\n",
    "    for ax,og in zip(axes,ogs):\n",
    "        # get values for x axis\n",
    "        oobs = obs.loc[obs.obgnme==og,:].copy()\n",
    "        oobs.loc[:,\"time\"] = oobs.time.astype(float)\n",
    "        oobs.sort_values(by=\"time\",inplace=True)\n",
    "        tvals = oobs.time.values\n",
    "        onames = oobs.obsnme.values\n",
    "        ylim = None\n",
    "        if pt_oe is not None:\n",
    "        # plot posterior\n",
    "            [ax.plot(tvals,pt_oe.loc[i,onames].values,\"b\",lw=0.5,alpha=0.5) for i in pt_oe.index]\n",
    "        # plot measured+noise \n",
    "        if noise is not None:\n",
    "            oobs = oobs.loc[oobs.weight>0,:]\n",
    "            tvals = oobs.time.values\n",
    "            onames = oobs.obsnme.values\n",
    "            [ax.plot(tvals,noise.loc[i,onames].values,\"r\",lw=0.5,alpha=0.5) for i in noise.index]\n",
    "            ax.scatter(oobs.time,oobs.obsval,marker='^',s=20,c=\"r\",zorder=10)\n",
    "            ylim = ax.get_ylim()\n",
    "        if pr_oe is not None:\n",
    "            # plot prior\n",
    "            [ax.plot(tvals,pr_oe.loc[i,onames].values,\"0.5\",lw=0.5,alpha=0.5,zorder=1) for i in pr_oe.index]\n",
    "        if ylim is not None:\n",
    "            ax.set_ylim(ylim)\n",
    "        ax.set_title(og,loc=\"left\")\n",
    "    _ = fig.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_pr_oe,org_pt_oe = pst.ies.obsen0,pst.ies.get(\"obsen\",pst.ies.phiactual.iteration.max())\n",
    "org_noise = pst.ies.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = plot_forecast_hist_compare(org_pr_oe,org_pt_oe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tseries_ensembles(org_pr_oe,org_pt_oe,org_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hk(org_pr_oe,org_pt_oe, pst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the posterior is more narrow than the noise - thats not good and it means that PESTPP-IES was not able to accomodate the noise during the assimilation process.\n",
    "\n",
    "Lets just see the noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tseries_ensembles(None,None,org_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about this for a minute.  With our representation of noise, do we care about \"high frequency\" temporal variation/randomness?  Thats what is being represented here:  each point in each timeseries is independent of all other points and maybe this is fine if we are trying to capture \"measurement noise\" only, but as we stated before, noise also needs to (try to) capture the effects of model error.  Let's also think about what the model can simulate:  looking back at the timeseries from posterior realizations - they have very little high-frequency components, so why are we trying to force the model to reproduce high-frequence noise?\n",
    "\n",
    "So how do we generate \"noise\" that is a) something the model can reproduce and b) represents not just measurement error, but all those other sources of error, include model error? There is not a single answer here other than \"it depends\", in that how you formulate and use noise will be very problem specific.  That being said, one interesting and relatively simple trick that can be done is to simply shift all the timeseries together by a constant amount - this is analogous to a \"constant\" multiplier parameter.  \n",
    "\n",
    "To do this, first lets just generate some standard normal deviates (random numbers from a normal distribution with mean of zero and standard deviation of one):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate standard normal deviates\n",
    "num_reals = pst.ies.paren0.shape[0]\n",
    "np.random.seed(pyemu.en.SEED)\n",
    "draws = np.random.normal(0,1,num_reals)\n",
    "_ = plt.hist(draws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets find the timeseries observations we want to apply these offsets to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "onames = obs.loc[(obs.weight>0) & (obs.oname.apply(lambda x: x in [\"hds\",\"sfr\"])),\"obsnme\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we are gonna do is first generate an observation noise ensemble using the `standard_deviation` column in the observation data - this will generate noise for all the non-zero weighted observations (including the difference obs).  Then we will replace the noise realizations for the timeseries observations such that each realization is the observation value plus one of the standard normal deviates we just generated, but this deviate will be applied to all timeseries obs at once, yielding extremely correlated observation noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first generate a standard noise ensemble \n",
    "newnoise = pyemu.ObservationEnsemble.from_gaussian_draw(pst=pst,cov=pyemu.Cov.from_observation_data(pst),num_reals=num_reals)\n",
    "newnoise.index = pst.ies.paren0.index\n",
    "ovals =  obs.loc[onames,\"obsval\"].values\n",
    "stdevs = obs.loc[onames,\"standard_deviation\"].values\n",
    "for i,draw in enumerate(draws):\n",
    "    newnoise.loc[i,onames] = ovals + (draw * stdevs)\n",
    "if \"base\" in newnoise.index:\n",
    "    newnoise.loc[\"base\",:] = obs.loc[newnoise.columns,\"obsval\"]\n",
    "newnoise.to_csv(os.path.join(t_d,\"extreme_noise.csv\"))\n",
    "pst.pestpp_options[\"ies_observation_ensemble\"] = \"extreme_noise.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PESTPP-IES\n",
    "\n",
    "Right then, let's do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update NOPTMAX again and re-write the control file\n",
    "pst.control_data.noptmax = -2\n",
    "pst.pestpp_options.pop(\"ies_bad_phi_sigma\",None)\n",
    "pst.write(os.path.join(t_d, 'pest.pst'),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies pest.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__Attention!__\n",
    "\n",
    "You must specify the number which is adequate for ***your*** machine! Make sure to assign an appropriate value for the following `num_workers` variable - if its too large for your machine, #badtimes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the number of physical cores avalable on your machine using `psutils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psutil.cpu_count(logical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 14 #update this according to your resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we shall specify the PEST run-manager/master directory folder as `m_d`. This is where outcomes of the PEST run will be recorded. It should be different from the `t_d` folder, which contains the \"template\" of the PEST dataset. This keeps everything separate and avoids silly mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = os.path.join('master_ies_1extreme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deploys the PEST agents and manager and then starts the run using PESTPP-IES. Run it by pressing `shift+enter`. If you wish to see the outputs in real-time, switch over to the terminal window (the one which you used to launch the `jupyter notebook`). There you should see PESTPP-IES's progress. \n",
    "\n",
    "If you open the tutorial folder, you should also see a bunch of new folders there named `worker_0`, `worker_1`, etc. These are the agent folders. The `master_ies` folder is where the manager is running. \n",
    "\n",
    "This run should take several minutes to complete (depending on the number of workers and the speed of your machine). If you get an error, make sure that your firewall or antivirus software is not blocking PESTPP-IES from communicating with the agents (this is a common problem!).\n",
    "\n",
    "> **Pro Tip**: Running PEST from within a `jupyter notebook` has a tendency to slow things down and hog alot of RAM. When modelling in the \"real world\" it is often more efficient to implement workflows in scripts which you can call from the command line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update NOPTMAX again and re-write the control file\n",
    "pst.control_data.noptmax = 5\n",
    "pst.write(os.path.join(t_d, 'pest.pst'),version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d, # the folder which contains the \"template\" PEST dataset\n",
    "                            'pestpp-ies', #the PEST software version we want to run\n",
    "                            'pest.pst', # the control file to use with PEST\n",
    "                            num_workers=num_workers, #how many agents to deploy\n",
    "                            worker_root='.', #where to deploy the agent directories; relative to where python is running\n",
    "                            master_dir=m_d, #the manager directory\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Outcomes\n",
    "\n",
    "Right then. PESTPP-IES completed successfully. Let's take a look at some of the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d,\"pest.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(10,3.5))\n",
    "# left\n",
    "ax = axes[0]\n",
    "phi = pst.ies.phiactual\n",
    "phi.index = phi.total_runs\n",
    "phi.iloc[:,6:].apply(np.log10).plot(legend=False,lw=0.5,color='k', ax=ax)\n",
    "ax.set_title(r'Actual $\\Phi$')\n",
    "ax.set_ylabel(r'log $\\Phi$')\n",
    "ax.grid()\n",
    "# right\n",
    "ax = axes[-1]\n",
    "phimeas = pst.ies.phimeas\n",
    "phimeas.index = phi.total_runs\n",
    "phimeas.iloc[:,6:].apply(np.log10).plot(legend=False,lw=0.2,color='r', ax=ax)\n",
    "ax.set_title(r'Measured+Noise $\\Phi$')\n",
    "ax.grid()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its important to notice that now the \"measured\" phi is behaving differently than the \"actual\" phi, and in fact, measured phi is substantially lower than the actual phi.  This is an outcome want to see because it indicates that PESTPP-IES is able to assimilate our representation of noise.\n",
    "\n",
    "Now lets inspect the observed vs simulated timeseries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_oe = pst.ies.obsen0\n",
    "pt_oe = pst.ies.get(\"obsen\",pst.ies.phiactual.iteration.max())\n",
    "noise = pst.ies.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_tseries_ensembles(None, pt_oe, noise, onames=[\"hds\",\"sfr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok!  Now that is a very different pattern from what we saw before.  Pay particular attention to how well the posterior simulated results (in blue) respect the noise realizations (in red).  Previously, we saw that the posterior was (much?) narrower than the noise realizations, indicating that PESTPP-IES was \"overfit\" WRT to the noise, this being an outcome of high-frequency statistically independent noise that could be not simulated/assimilated, which presented \"irreducible residuals\" to PESTPP-IES, in which case PESTPP-IES simple \"shot through the middle\".  But now, we have corresondence between the noise and posterior.  Conceptually, these noise realizations have forced PESTPP-IES to find parameter sets that yield simulation results that are consistently higher or lower than the observed values.  Maybe, for your settings, model, and prediction(s) this is what you want (Also, credit Eduardo de Sousa for this idea!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_hk(pr_oe,pt_oe, pst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_forecast_hist_compare(pr_oe,pt_oe,last_prior=org_pr_oe,last_pt_oe=org_pt_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that just messing with the noise has a nontrivial influence over the important predictive outcomes...kinda scary...\n",
    "\n",
    "So that is a short exploration of noise and how it is used within ensemble methods.  Just like when design the parameterization and the Prior, and the weighting strategy, designing a clever and appropriate noise scheme will be problem specific and require considerable common (or hydro) sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
